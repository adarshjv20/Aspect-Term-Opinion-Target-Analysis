{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\y-500\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\users\\y-500\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlps = spacy.load('en')\n",
    "#from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize,sent_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC, NuSVC,SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import spacy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score,precision_score,recall_score, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import re\n",
    "#from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(message):\n",
    "    message = message.replace(\"[comma]\",\",\")\n",
    "    message = \" \".join(wordpunct_tokenize(message))\n",
    "    nopunc = [char for char in message if char not in string.punctuation]\n",
    "    message = \"\".join(nopunc)\n",
    "    message = [text for text in message.strip().split() if text not in set(stopwords.words('english'))]    \n",
    "    message = \" \".join(message)\n",
    "    return word_tokenize(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = pd.read_csv('data 2_train.csv')\n",
    "df_copy.columns = ['example_id','text','aspect_term','term_location','class']\n",
    "df2 = df_copy.copy()\n",
    "countVectorizer = CountVectorizer()\n",
    "document_term_matrix = countVectorizer.fit_transform(df2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3716"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(countVectorizer.vocabulary_.keys())\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>term_location</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3121_0</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>staff</td>\n",
       "      <td>8--13</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2777_0</td>\n",
       "      <td>To be completely fair[comma] the only redeemin...</td>\n",
       "      <td>food</td>\n",
       "      <td>57--61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1634_0</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>food</td>\n",
       "      <td>4--8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1634_1</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>55--62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1634_2</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>menu</td>\n",
       "      <td>141--145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  example_id                                               text aspect_term  \\\n",
       "0     3121_0               But the staff was so horrible to us.       staff   \n",
       "1     2777_0  To be completely fair[comma] the only redeemin...        food   \n",
       "2     1634_0  The food is uniformly exceptional[comma] with ...        food   \n",
       "3     1634_1  The food is uniformly exceptional[comma] with ...     kitchen   \n",
       "4     1634_2  The food is uniformly exceptional[comma] with ...        menu   \n",
       "\n",
       "  term_location  class  \n",
       "0         8--13     -1  \n",
       "1        57--61      1  \n",
       "2          4--8      1  \n",
       "3        55--62      1  \n",
       "4      141--145      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text'] = df2['text'].apply(pre_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list = []\n",
    "df2['pp_aspect_term'] = df2['aspect_term'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(x):\n",
    "    text = x[0]\n",
    "    aspect = x[1]\n",
    "    if set(aspect) <= set(text):\n",
    "        left_weights = right_weights = []\n",
    "        sentence = \" \".join(text)\n",
    "        aspect_join = \" \".join(aspect)\n",
    "        start_list= [i for i, x in enumerate(text) if x == aspect[0]]\n",
    "        for q in (start_list):\n",
    "            if  text[(q + len(aspect) - 1)] == aspect[-1]:\n",
    "                start_index = q\n",
    "                end_index = q + len(aspect) - 1\n",
    "                break\n",
    "        if (end_index - start_index) == len(aspect) - 1:\n",
    "            left_text = text[:start_index]\n",
    "            right_text = text[end_index+1:]\n",
    "            left_weights = [1/i for i in range(len(left_text),0,-1) if len(left_text) != 0]\n",
    "            right_weights = [1/i for i in range(1,len(right_text)+1) if len(right_text) != 0]\n",
    "        tot_weights = left_weights + [2]*len(aspect) + right_weights\n",
    "        return dict(zip(text,tot_weights))\n",
    "    else: \n",
    "        return np.nan\n",
    "            #return right_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['weights_score'] = df2[['text','pp_aspect_term']].apply(calculate_weights, axis = 1)\n",
    "weight_list.append(df2[['text','pp_aspect_term']].apply(calculate_weights, axis = 1))\n",
    "df2 = df2.dropna()\n",
    "df_created = pd.DataFrame(np.zeros((len(df2),len(vocab))),columns=vocab)\n",
    "bow_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(df2)):\n",
    "    for key,value in df2.iloc[row]['weights_score'].items():\n",
    "        df_created.iloc[row][key] = value\n",
    "\n",
    "tfidf= TfidfTransformer().fit_transform(df_created)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(C=1.2)\n",
    "pred_weights = cross_val_predict(svm,tfidf,df2['class'],cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6683333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred_weights == df2['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6305555555555555"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "pred_weight_mnb = cross_val_predict(mnb,tfidf,df2['class'],cv = 10)\n",
    "np.mean(pred_weight_mnb == df2['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6552777777777777"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50,max_depth=1500)\n",
    "pred_weight_rfc = cross_val_predict(rfc,tfidf,df2['class'],cv = 10)\n",
    "np.mean(pred_weight_rfc == df2['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.55759599, 0.44295302, 0.73375098]), array([0.41542289, 0.31279621, 0.86638927]), array([0.47612259, 0.36666667, 0.79457282]), array([ 804,  633, 2163], dtype=int64))\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.42      0.56      0.48       599\n",
      "          0       0.31      0.44      0.37       447\n",
      "          1       0.87      0.73      0.79      2554\n",
      "\n",
      "avg / total       0.72      0.67      0.69      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y = df2['class']\n",
    "print(precision_recall_fscore_support(Y, pred_weights, labels=[-1,0,1]))\n",
    "print(\"\\n Classification Report \\n \", classification_report(pred_weights,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6555555555555556"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators=40)\n",
    "pred_weight_etc = cross_val_predict(etc,tfidf,df2['class'],cv = 10)\n",
    "np.mean(pred_weight_etc == df2['class'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
