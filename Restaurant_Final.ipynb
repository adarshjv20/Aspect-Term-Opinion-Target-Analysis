{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize,sent_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Restaurant_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>term_location</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3121_0</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>staff</td>\n",
       "      <td>8--13</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2777_0</td>\n",
       "      <td>To be completely fair[comma] the only redeemin...</td>\n",
       "      <td>food</td>\n",
       "      <td>57--61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1634_0</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>food</td>\n",
       "      <td>4--8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1634_1</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>55--62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1634_2</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>menu</td>\n",
       "      <td>141--145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  example_id                                               text  aspect_term  \\\n",
       "0     3121_0               But the staff was so horrible to us.        staff   \n",
       "1     2777_0  To be completely fair[comma] the only redeemin...         food   \n",
       "2     1634_0  The food is uniformly exceptional[comma] with ...         food   \n",
       "3     1634_1  The food is uniformly exceptional[comma] with ...      kitchen   \n",
       "4     1634_2  The food is uniformly exceptional[comma] with ...         menu   \n",
       "\n",
       "   term_location   class  \n",
       "0          8--13      -1  \n",
       "1         57--61       1  \n",
       "2           4--8       1  \n",
       "3         55--62       1  \n",
       "4       141--145       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.columns = ['example_id','text','aspect_term','term_location','class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVectorizer = CountVectorizer()\n",
    "document_matrix = countVectorizer.fit_transform(data_copy['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3716"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(countVectorizer.vocabulary_.keys())\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(message):\n",
    "    message = message.replace(\"[comma]\",\",\")\n",
    "    message = \" \".join(wordpunct_tokenize(message))\n",
    "    nopunc = [char for char in message if char not in string.punctuation]\n",
    "    message = \"\".join(nopunc)\n",
    "    message = [text for text in message.strip().split() if text not in set(stopwords.words('english'))]    \n",
    "    message = \" \".join(message)\n",
    "    return word_tokenize(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy['text'] = data_copy['text'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           [But, staff, horrible, us]\n",
       "1    [To, completely, fair, redeeming, factor, food...\n",
       "2    [The, food, uniformly, exceptional, capable, k...\n",
       "3    [The, food, uniformly, exceptional, capable, k...\n",
       "4    [The, food, uniformly, exceptional, capable, k...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy['mod_aspect_term'] = data_copy['aspect_term'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(x):\n",
    "    text = x[0]\n",
    "    aspect = x[1]\n",
    "    if set(aspect) <= set(text):\n",
    "        left_weights = right_weights = []\n",
    "        sentence = \" \".join(text)\n",
    "        aspect_join = \" \".join(aspect)\n",
    "        start_list= [i for i, x in enumerate(text) if x == aspect[0]]\n",
    "        for q in (start_list):\n",
    "            if  text[(q + len(aspect) - 1)] == aspect[-1]:\n",
    "                start_index = q\n",
    "                end_index = q + len(aspect) - 1\n",
    "                break\n",
    "        if (end_index - start_index) == len(aspect) - 1:\n",
    "            left_text = text[:start_index]\n",
    "            right_text = text[end_index+1:]\n",
    "            left_weights = [1/i for i in range(len(left_text),0,-1) if len(left_text) != 0]\n",
    "            right_weights = [1/i for i in range(1,len(right_text)+1) if len(right_text) != 0]\n",
    "        tot_weights = left_weights + [2]*len(aspect) + right_weights\n",
    "        return dict(zip(text,tot_weights))\n",
    "    else: \n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy['weights_score'] = data_copy[['text','mod_aspect_term']].apply(calculate_weights, axis = 1)\n",
    "data_copy = data_copy.dropna()\n",
    "df_new = pd.DataFrame(np.zeros((len(data_copy),len(vocab))),columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'But': 1.0, 'staff': 2, 'horrible': 1.0, 'us'...\n",
       "1    {'To': 0.2, 'completely': 0.25, 'fair': 0.3333...\n",
       "2    {'The': 1.0, 'food': 2, 'uniformly': 1.0, 'exc...\n",
       "3    {'The': 0.2, 'food': 0.25, 'uniformly': 0.3333...\n",
       "4    {'The': 0.07692307692307693, 'food': 0.0833333...\n",
       "Name: weights_score, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy['weights_score'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(data_copy)):\n",
    "    for key,value in data_copy.iloc[row]['weights_score'].items():\n",
    "        df_new.iloc[row][key] = value\n",
    "\n",
    "tfidf= TfidfTransformer().fit_transform(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Val on RBF SVM Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6008333333333333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(C=1.2,random_state=0)\n",
    "pred_weight_svc = cross_val_predict(svc,tfidf,data_copy['class'],cv = 10)\n",
    "np.mean(pred_weight_svc == data_copy['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Val on Linear SVM kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6683333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(C=1.2,random_state=0)\n",
    "pred_weight_svm = cross_val_predict(svm,tfidf,data_copy['class'],cv = 10)\n",
    "np.mean(pred_weight_svm == data_copy['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Val on MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6305555555555555"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "pred_weight_mnb = cross_val_predict(mnb,tfidf,data_copy['class'],cv = 10)\n",
    "np.mean(pred_weight_mnb == data_copy['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Val on Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6525"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50,max_depth=1500,random_state=0)\n",
    "pred_weight_rfc = cross_val_predict(rfc,tfidf,data_copy['class'],cv = 10)\n",
    "np.mean(pred_weight_rfc == data_copy['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Random Forrest Metrics\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.32      0.60      0.42       430\n",
      "          0       0.18      0.38      0.25       305\n",
      "          1       0.91      0.69      0.79      2865\n",
      "\n",
      "avg / total       0.78      0.65      0.70      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Random Forrest Metrics\\n \", classification_report(pred_weight_rfc,data_copy['class']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(tfidf,data_copy['class'],test_size = 0.3,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7111111111111111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(C=1.2,random_state=0).fit(X=x_train,y=y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.712037037037037"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=50,max_depth=1500,random_state=0).fit(X=x_train,y=y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model using Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=50,max_depth=1500,random_state=0).fit(tfidf,y=data_copy['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('Data-2_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.columns = ['example_id','text','aspect_term','term_location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>term_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32933228#1700177#1_2</td>\n",
       "      <td>I reccomend the fried pork dumplings[comma] th...</td>\n",
       "      <td>fried rice</td>\n",
       "      <td>71--81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35820984#608922#3_0</td>\n",
       "      <td>The staff is very sharp and they look good too.</td>\n",
       "      <td>staff</td>\n",
       "      <td>4--9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35170181#0#5_1</td>\n",
       "      <td>The best dessert[comma] a chocolate and peanut...</td>\n",
       "      <td>chocolate and peanut butter tart</td>\n",
       "      <td>20--52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33067279#1612676#1_1</td>\n",
       "      <td>The food was very good and I was pleasantly su...</td>\n",
       "      <td>vegan options</td>\n",
       "      <td>69--82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32882616#562969#3_0</td>\n",
       "      <td>I never had an orange donut before so I gave i...</td>\n",
       "      <td>orange donut</td>\n",
       "      <td>15--27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             example_id                                               text  \\\n",
       "0  32933228#1700177#1_2  I reccomend the fried pork dumplings[comma] th...   \n",
       "1   35820984#608922#3_0    The staff is very sharp and they look good too.   \n",
       "2        35170181#0#5_1  The best dessert[comma] a chocolate and peanut...   \n",
       "3  33067279#1612676#1_1  The food was very good and I was pleasantly su...   \n",
       "4   32882616#562969#3_0  I never had an orange donut before so I gave i...   \n",
       "\n",
       "                        aspect_term term_location  \n",
       "0                        fried rice        71--81  \n",
       "1                             staff          4--9  \n",
       "2  chocolate and peanut butter tart        20--52  \n",
       "3                     vegan options        69--82  \n",
       "4                      orange donut        15--27  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['text'] = test_data['text'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['mod_aspect_term'] = test_data['aspect_term'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['weights_score'] = test_data[['text','mod_aspect_term']].apply(calculate_weights, axis = 1)\n",
    "test_data = test_data.dropna()\n",
    "df_test = pd.DataFrame(np.zeros((len(test_data),len(vocab))),columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(test_data)):\n",
    "    for key,value in test_data.iloc[row]['weights_score'].items():\n",
    "        df_test.iloc[row][key] = value\n",
    "\n",
    "tfidf_test= TfidfTransformer().fit_transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['class']=(model.predict(tfidf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy['class'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
